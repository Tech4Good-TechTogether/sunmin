{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "hand_landmarks_dict = {\n",
    "    0: \"WRIST\",\n",
    "    1: \"THUMB_CMC\",\n",
    "    2: \"THUMB_MCP\",\n",
    "    3: \"THUMB_IP\",\n",
    "    4: \"THUMB_TIP\",\n",
    "    5: \"INDEX_FINGER_MCP\",\n",
    "    6: \"INDEX_FINGER_PIP\",\n",
    "    7: \"INDEX_FINGER_DIP\",\n",
    "    8: \"INDEX_FINGER_TIP\",\n",
    "    9: \"MIDDLE_FINGER_MCP\",\n",
    "    10: \"MIDDLE_FINGER_PIP\",\n",
    "    11: \"MIDDLE_FINGER_DIP\",\n",
    "    12: \"MIDDLE_FINGER_TIP\",\n",
    "    13: \"RING_FINGER_MCP\",\n",
    "    14: \"RING_FINGER_PIP\",\n",
    "    15: \"RING_FINGER_DIP\",\n",
    "    16: \"RING_FINGER_TIP\",\n",
    "    17: \"PINKY_MCP\",\n",
    "    18: \"PINKY_PIP\",\n",
    "    19: \"PINKY_DIP\",\n",
    "    20: \"PINKY_TIP\"\n",
    "}\n",
    "\n",
    "# 손 랜드마크 추출 함수\n",
    "def get_hand_landmarks(frame, hands):\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(image_rgb)\n",
    "    if result.multi_hand_landmarks:\n",
    "        landmarks = []\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.append([lm.x, lm.y, lm.z])\n",
    "        return np.array(landmarks)\n",
    "    return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# 손 랜드마크 번호를 미리 정의\n",
    "hand_landmarks_dict = {\n",
    "    0: \"WRIST\",\n",
    "    1: \"THUMB_CMC\",\n",
    "    2: \"THUMB_MCP\",\n",
    "    3: \"THUMB_IP\",\n",
    "    4: \"THUMB_TIP\",\n",
    "    5: \"INDEX_FINGER_MCP\",\n",
    "    6: \"INDEX_FINGER_PIP\",\n",
    "    7: \"INDEX_FINGER_DIP\",\n",
    "    8: \"INDEX_FINGER_TIP\",\n",
    "    9: \"MIDDLE_FINGER_MCP\",\n",
    "    10: \"MIDDLE_FINGER_PIP\",\n",
    "    11: \"MIDDLE_FINGER_DIP\",\n",
    "    12: \"MIDDLE_FINGER_TIP\",\n",
    "    13: \"RING_FINGER_MCP\",\n",
    "    14: \"RING_FINGER_PIP\",\n",
    "    15: \"RING_FINGER_DIP\",\n",
    "    16: \"RING_FINGER_TIP\",\n",
    "    17: \"PINKY_MCP\",\n",
    "    18: \"PINKY_PIP\",\n",
    "    19: \"PINKY_DIP\",\n",
    "    20: \"PINKY_TIP\"\n",
    "}\n",
    "\n",
    "# 손 랜드마크 추출 함수\n",
    "def get_hand_landmarks(frame, hands):\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(image_rgb)\n",
    "    if result.multi_hand_landmarks:\n",
    "        landmarks = []\n",
    "        for hand_landmarks in result.multi_hand_landmarks:\n",
    "            for lm in hand_landmarks.landmark:\n",
    "                landmarks.append([lm.x, lm.y, lm.z])\n",
    "        return np.array(landmarks)\n",
    "    return []\n",
    "\n",
    "# Cosine Similarity 계산 함수\n",
    "def calculate_similarity(hand1, hand2):\n",
    "    if hand1 is not None and hand2 is not None:\n",
    "        # 유사도 계산\n",
    "        hand1_flat = hand1.flatten().reshape(1, -1)\n",
    "        hand2_flat = hand2.flatten().reshape(1, -1)\n",
    "        similarity = cosine_similarity(hand1_flat, hand2_flat)[0][0]\n",
    "        return similarity\n",
    "    return 0\n",
    "\n",
    "# 두 벡터 간의 각도 계산 함수\n",
    "def calculate_angle(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    magnitude_v1 = np.linalg.norm(v1)\n",
    "    magnitude_v2 = np.linalg.norm(v2)\n",
    "    cos_angle = dot_product / (magnitude_v1 * magnitude_v2)\n",
    "    angle = np.arccos(cos_angle)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "# 동작 감지, 각도 측정 함수\n",
    "def detect_hand_interactions(landmarks, angle_threshold=80, angle_range=10): # 실험해보고 정함 (90도가 이상적인데, 해보니까 잘 안나옴) # 80이하는 정확도가 너무 낮아짐\n",
    "    if len(landmarks) == 21:  # 한 손이 감지된 경우\n",
    "        wrist = landmarks[0]\n",
    "        thumb_tip = landmarks[4]\n",
    "        index_tip = landmarks[8]\n",
    "        \n",
    "        # 벡터 계산\n",
    "        v1 = np.array(thumb_tip) - np.array(wrist)\n",
    "        v2 = np.array(index_tip) - np.array(wrist)\n",
    "        \n",
    "        # 두 벡터 간의 각도 계산\n",
    "        angle = calculate_angle(v1, v2)\n",
    "        \n",
    "        if angle_threshold <= angle <= (angle_threshold + angle_range):\n",
    "            return angle, True\n",
    "        else:\n",
    "            return angle, False\n",
    "    return None, False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_12_0_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/sophia/miniconda3/envs/hana/lib/python3.9/site-packages (from opencv-python) (2.0.1)\n",
      "Downloading opencv_python-4.10.0.84-cp37-abi3-macosx_12_0_x86_64.whl (56.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.10.0.84\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.5.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/sophia/miniconda3/envs/hana/lib/python3.9/site-packages (from scikit-learn) (2.0.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/sophia/miniconda3/envs/hana/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Using cached scikit_learn-1.5.1-cp39-cp39-macosx_10_9_x86_64.whl (12.1 MB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 타겟 비디오의 손 관절 측정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 색상 팔레트\n",
    "colors={\n",
    "    \"purple_1\":[120, 58, 221],\n",
    "    \"purple_2\":[147, 97, 228],\n",
    "    \"purple_3\":[174, 137, 235],\n",
    "    \"purple_4\":[201, 176, 241],\n",
    "    \"purple_5\":[228, 216, 248]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724223907.044541 2429755 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1 Pro\n",
      "W0000 00:00:1724223907.058501 2926766 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1724223907.078361 2926760 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "# 비디오 파일 경로\n",
    "video_path = \"../demo.mp4\"  # 여기에 비디오 파일 경로를 입력하세요\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 첫 번째 프레임 읽기\n",
    "ret, first_frame = cap.read()\n",
    "mp_hands = mp.solutions.hands\n",
    "target_rgb = cv2.cvtColor(first_frame, cv2.COLOR_BGR2RGB)\n",
    "target_result = mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7, min_tracking_confidence=0.7).process(target_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[landmark {\n",
       "   x: 0.735671878\n",
       "   y: 0.438989729\n",
       "   z: 1.81169199e-07\n",
       " }\n",
       " landmark {\n",
       "   x: 0.689108193\n",
       "   y: 0.370228887\n",
       "   z: -0.00946707651\n",
       " }\n",
       " landmark {\n",
       "   x: 0.634040654\n",
       "   y: 0.351166785\n",
       "   z: -0.0173024926\n",
       " }\n",
       " landmark {\n",
       "   x: 0.586739719\n",
       "   y: 0.326370806\n",
       "   z: -0.0223623514\n",
       " }\n",
       " landmark {\n",
       "   x: 0.559816122\n",
       "   y: 0.274949491\n",
       "   z: -0.0279654562\n",
       " }\n",
       " landmark {\n",
       "   x: 0.614430904\n",
       "   y: 0.442905277\n",
       "   z: -0.0283782203\n",
       " }\n",
       " landmark {\n",
       "   x: 0.551114798\n",
       "   y: 0.448273182\n",
       "   z: -0.0340142436\n",
       " }\n",
       " landmark {\n",
       "   x: 0.514758587\n",
       "   y: 0.443601102\n",
       "   z: -0.037010204\n",
       " }\n",
       " landmark {\n",
       "   x: 0.486967474\n",
       "   y: 0.443099797\n",
       "   z: -0.039922554\n",
       " }\n",
       " landmark {\n",
       "   x: 0.621275544\n",
       "   y: 0.505222678\n",
       "   z: -0.0236355215\n",
       " }\n",
       " landmark {\n",
       "   x: 0.572940767\n",
       "   y: 0.486672\n",
       "   z: -0.0236896481\n",
       " }\n",
       " landmark {\n",
       "   x: 0.582831323\n",
       "   y: 0.452062309\n",
       "   z: -0.0171936732\n",
       " }\n",
       " landmark {\n",
       "   x: 0.601314425\n",
       "   y: 0.438074529\n",
       "   z: -0.0143165588\n",
       " }\n",
       " landmark {\n",
       "   x: 0.634251773\n",
       "   y: 0.549080908\n",
       "   z: -0.0177848656\n",
       " }\n",
       " landmark {\n",
       "   x: 0.59098506\n",
       "   y: 0.522430241\n",
       "   z: -0.0151578048\n",
       " }\n",
       " landmark {\n",
       "   x: 0.599050879\n",
       "   y: 0.490965933\n",
       "   z: -0.00631147902\n",
       " }\n",
       " landmark {\n",
       "   x: 0.616447568\n",
       "   y: 0.47951138\n",
       "   z: -0.00303764315\n",
       " }\n",
       " landmark {\n",
       "   x: 0.647151589\n",
       "   y: 0.578243613\n",
       "   z: -0.0126295136\n",
       " }\n",
       " landmark {\n",
       "   x: 0.611152828\n",
       "   y: 0.557643\n",
       "   z: -0.0100295199\n",
       " }\n",
       " landmark {\n",
       "   x: 0.616629839\n",
       "   y: 0.530096769\n",
       "   z: -0.00312221586\n",
       " }\n",
       " landmark {\n",
       "   x: 0.630087793\n",
       "   y: 0.519245207\n",
       "   z: 0.000929739443\n",
       " },\n",
       " landmark {\n",
       "   x: 0.343726903\n",
       "   y: 0.451420844\n",
       "   z: 1.13293865e-07\n",
       " }\n",
       " landmark {\n",
       "   x: 0.389960527\n",
       "   y: 0.467829555\n",
       "   z: -0.00639455765\n",
       " }\n",
       " landmark {\n",
       "   x: 0.427807063\n",
       "   y: 0.447448045\n",
       "   z: -0.0208901931\n",
       " }\n",
       " landmark {\n",
       "   x: 0.459632456\n",
       "   y: 0.438421577\n",
       "   z: -0.0372109972\n",
       " }\n",
       " landmark {\n",
       "   x: 0.489745855\n",
       "   y: 0.441799164\n",
       "   z: -0.0538028069\n",
       " }\n",
       " landmark {\n",
       "   x: 0.43618834\n",
       "   y: 0.325059325\n",
       "   z: -0.0329814218\n",
       " }\n",
       " landmark {\n",
       "   x: 0.48428458\n",
       "   y: 0.305282801\n",
       "   z: -0.0589928664\n",
       " }\n",
       " landmark {\n",
       "   x: 0.519526899\n",
       "   y: 0.289290249\n",
       "   z: -0.0745016783\n",
       " }\n",
       " landmark {\n",
       "   x: 0.546202898\n",
       "   y: 0.269207388\n",
       "   z: -0.0847458616\n",
       " }\n",
       " landmark {\n",
       "   x: 0.414781719\n",
       "   y: 0.312749386\n",
       "   z: -0.0435049199\n",
       " }\n",
       " landmark {\n",
       "   x: 0.466886938\n",
       "   y: 0.3966901\n",
       "   z: -0.0743451267\n",
       " }\n",
       " landmark {\n",
       "   x: 0.451570034\n",
       "   y: 0.460451275\n",
       "   z: -0.07592801\n",
       " }\n",
       " landmark {\n",
       "   x: 0.431974918\n",
       "   y: 0.473824233\n",
       "   z: -0.0717891529\n",
       " }\n",
       " landmark {\n",
       "   x: 0.391184032\n",
       "   y: 0.333287954\n",
       "   z: -0.054396566\n",
       " }\n",
       " landmark {\n",
       "   x: 0.436256379\n",
       "   y: 0.427535\n",
       "   z: -0.0827391\n",
       " }\n",
       " landmark {\n",
       "   x: 0.424672782\n",
       "   y: 0.473554641\n",
       "   z: -0.0726333633\n",
       " }\n",
       " landmark {\n",
       "   x: 0.409001589\n",
       "   y: 0.469986379\n",
       "   z: -0.0603967197\n",
       " }\n",
       " landmark {\n",
       "   x: 0.368963748\n",
       "   y: 0.369211763\n",
       "   z: -0.065889582\n",
       " }\n",
       " landmark {\n",
       "   x: 0.405814052\n",
       "   y: 0.438731551\n",
       "   z: -0.0824586749\n",
       " }\n",
       " landmark {\n",
       "   x: 0.404217184\n",
       "   y: 0.474985063\n",
       "   z: -0.0724023283\n",
       " }\n",
       " landmark {\n",
       "   x: 0.393380016\n",
       "   y: 0.473442793\n",
       "   z: -0.0616968945\n",
       " }]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_result.multi_hand_landmarks[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 해상도: 1920x1080 현재 fps:30.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724224568.839961 2429755 gl_context.cc:357] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1 Pro\n",
      "W0000 00:00:1724224568.849600 3296062 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1724224568.857050 3296062 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 55\u001b[0m\n\u001b[1;32m     53\u001b[0m target_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(target_frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     54\u001b[0m web_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(web_frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[0;32m---> 55\u001b[0m target_result \u001b[38;5;241m=\u001b[39m \u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_rgb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m web_result \u001b[38;5;241m=\u001b[39m hands\u001b[38;5;241m.\u001b[39mprocess(web_rgb)\n\u001b[1;32m     58\u001b[0m current_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/miniconda3/envs/hana/lib/python3.9/site-packages/mediapipe/python/solutions/hands.py:153\u001b[0m, in \u001b[0;36mHands.process\u001b[0;34m(self, image)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m, image: np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NamedTuple:\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Processes an RGB image and returns the hand landmarks and handedness of each detected hand.\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m         right hand) of the detected hand.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hana/lib/python3.9/site-packages/mediapipe/python/solution_base.py:340\u001b[0m, in \u001b[0;36mSolutionBase.process\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_graph\u001b[38;5;241m.\u001b[39madd_packet_to_input_stream(\n\u001b[1;32m    336\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream_name,\n\u001b[1;32m    337\u001b[0m         packet\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_packet(input_stream_type,\n\u001b[1;32m    338\u001b[0m                                  data)\u001b[38;5;241m.\u001b[39mat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_simulated_timestamp))\n\u001b[0;32m--> 340\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_graph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_until_idle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Create a NamedTuple object where the field names are mapping to the graph\u001b[39;00m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;66;03m# output stream names.\u001b[39;00m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_stream_type_info \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "\n",
    "# Mediapipe 손 모델 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 색상 및 두께 지정\n",
    "landmark_drawing_spec = mp_drawing.DrawingSpec(color=colors[\"purple_2\"], thickness=2) \n",
    "connection_drawing_spec = mp_drawing.DrawingSpec(color=colors[\"purple_1\"], thickness=2) \n",
    "\n",
    "\n",
    "# 비디오 파일 경로\n",
    "video_path = \"../demo.mp4\"  # 여기에 비디오 파일 경로를 입력하세요\n",
    "target_cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "web_cap = cv2.VideoCapture(0)\n",
    "# 첫 번째 프레임 읽기\n",
    "ret, first_frame = target_cap.read()\n",
    "\n",
    "# 동작 및 각도 측정을 위한 변수 초기화\n",
    "movement_count = 0\n",
    "angle_threshold = 80  # 각도 임계값\n",
    "angle_range = 10  # 각도 범위\n",
    "\n",
    "start_time = time.time()\n",
    "while(True):\n",
    "    # 해상도 설정\n",
    "    frame_width = int(web_cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(web_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = web_cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    print(f'현재 해상도: {frame_width}x{frame_height}', f'현재 fps:{fps}')\n",
    "\n",
    "    web_cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)  # 가로 해상도\n",
    "    web_cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 360)  # 세로 해상도\n",
    "\n",
    "    # 프레임 속도 설정 (예: 30 FPS)\n",
    "    web_cap.set(cv2.CAP_PROP_FPS, 30)  # 초당 프레임 수\n",
    "    \n",
    "    with mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7, min_tracking_confidence=0.7) as hands:\n",
    "        while web_cap.isOpened():\n",
    "            target_ret, target_frame = target_cap.read()\n",
    "            web_ret, web_frame = web_cap.read()\n",
    "            if not web_ret:\n",
    "                break\n",
    "            if not target_ret:\n",
    "                break\n",
    "\n",
    "            # 타겟 손 랜드마크 추출\n",
    "            target_rgb = cv2.cvtColor(target_frame, cv2.COLOR_BGR2RGB)\n",
    "            web_rgb = cv2.cvtColor(web_frame, cv2.COLOR_BGR2RGB)\n",
    "            target_result = hands.process(target_rgb)\n",
    "            web_result = hands.process(web_rgb)\n",
    "            \n",
    "            current_time = time.time()\n",
    "                 \n",
    "            # 재활자의 랜드마크 표시\n",
    "            if web_result.multi_hand_landmarks:\n",
    "                for web_landmarks in web_result.multi_hand_landmarks:\n",
    "                    mp_drawing.draw_landmarks(web_frame, web_landmarks, mp_hands.HAND_CONNECTIONS,\n",
    "                                            landmark_drawing_spec,\n",
    "                                            connection_drawing_spec)\n",
    "                    \n",
    "                    # 동작 및 각도 감지\n",
    "                    landmarks = get_hand_landmarks(web_frame, hands)\n",
    "                    angle, detected = detect_hand_interactions(landmarks)\n",
    "                    \n",
    "                    if detected:\n",
    "                        global interaction_detected, movement_count\n",
    "                        if not interaction_detected:\n",
    "                            interaction_detected = True\n",
    "                            movement_count += 1\n",
    "                    else:\n",
    "                        interaction_detected = False\n",
    "                    \n",
    "                    if angle is not None:\n",
    "                        cv2.putText(web_frame, f'Angle: {angle:.2f}', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "                    \n",
    "            \n",
    "            # # 타겟 랜드마크 표시\n",
    "            # if target_result.multi_hand_landmarks:\n",
    "            #     for target_landmarks in target_result.multi_hand_landmarks:\n",
    "            #         # mp_drawing.draw_landmarks(target_frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "            #         mp_drawing.draw_landmarks(web_frame, target_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "                    \n",
    "                    \n",
    "            # 운동 시간 출력   \n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            # 경과 시간을 분:초 형식으로 변환\n",
    "            hours = int(elapsed_time//3600)\n",
    "            minutes = int(elapsed_time // 60)\n",
    "            seconds = int(elapsed_time % 60)\n",
    "            time_text = f'Time: :{minutes:02}:{seconds:02}'     \n",
    "            cv2.putText(web_frame, time_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            # 동작 횟수 출력\n",
    "            cv2.putText(web_frame, f'Movement Count: {movement_count}', (10, 110), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "            # 화면에 프레임 표시\n",
    "            cv2.imshow('Hand Tracking', web_frame)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                target_cap.release()\n",
    "                cv2.destroyAllWindows()\n",
    "                exit()\n",
    "    target_cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "end_time=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력된 비디오의 두손 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1724215070.474400       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 88.1), renderer: Apple M1\n"
     ]
    }
   ],
   "source": [
    "# Mediapipe 손 모델 초기화\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 비디오 캡처 초기화\n",
    "target_cap = cv2.VideoCapture(0)\n",
    "\n",
    "with mp_hands.Hands(max_num_hands=2, min_detection_confidence=0.7, min_tracking_confidence=0.7) as hands:\n",
    "    while target_cap.isOpened():\n",
    "        target_ret, target_frame = target_cap.read()\n",
    "        if not target_ret:\n",
    "            break\n",
    "\n",
    "        # 손 랜드마크 추출\n",
    "        hand_landmarks = get_hand_landmarks(target_frame, hands)\n",
    "\n",
    "        # 손 유사도 계산 (두 손이 모두 인식된 경우)\n",
    "        if hand_landmarks is not None and len(hand_landmarks) == 42:  # 두 손 모두 21개 랜드마크씩 총 42개\n",
    "            hand1 = hand_landmarks[:21]\n",
    "            hand2 = hand_landmarks[21:]\n",
    "            similarity = calculate_similarity(hand1, hand2)\n",
    "            cv2.putText(target_frame, f'Similarity: {similarity:.2f}', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "        # 랜드마크 시각화\n",
    "        # if hand_landmarks is not None:\n",
    "        #     for hand_landmark in hand_landmarks.reshape(-1, 21, 3):\n",
    "        #         mp_drawing.draw_landmarks(frame, mp_hands.HandLandmarkList(landmark=hand_landmark))\n",
    "\n",
    "        cv2.imshow('Hand Tracking', target_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "target_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 입력된 비디오의 동작 횟수 측정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tech4good",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
